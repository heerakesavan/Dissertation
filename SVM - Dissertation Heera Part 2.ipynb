{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\heera\\Desktop\\Dissertation\\Data Physionet\\traindata\\merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-577.74457</td>\n",
       "      <td>116.68117</td>\n",
       "      <td>82.454210</td>\n",
       "      <td>40.931873</td>\n",
       "      <td>7.485605</td>\n",
       "      <td>-7.887007</td>\n",
       "      <td>-4.491601</td>\n",
       "      <td>10.008358</td>\n",
       "      <td>24.508472</td>\n",
       "      <td>30.438593</td>\n",
       "      <td>...</td>\n",
       "      <td>5.994569</td>\n",
       "      <td>5.839570</td>\n",
       "      <td>3.671601</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>-1.004319</td>\n",
       "      <td>-1.004396</td>\n",
       "      <td>0.530715</td>\n",
       "      <td>2.398161</td>\n",
       "      <td>3.331668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-628.81630</td>\n",
       "      <td>136.51126</td>\n",
       "      <td>100.357864</td>\n",
       "      <td>56.209590</td>\n",
       "      <td>19.551243</td>\n",
       "      <td>0.428206</td>\n",
       "      <td>-0.259094</td>\n",
       "      <td>10.158183</td>\n",
       "      <td>21.104572</td>\n",
       "      <td>24.655876</td>\n",
       "      <td>...</td>\n",
       "      <td>3.507886</td>\n",
       "      <td>2.841200</td>\n",
       "      <td>1.227278</td>\n",
       "      <td>-0.146953</td>\n",
       "      <td>-0.405241</td>\n",
       "      <td>0.449801</td>\n",
       "      <td>1.629177</td>\n",
       "      <td>2.186590</td>\n",
       "      <td>1.692338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-601.18340</td>\n",
       "      <td>77.22223</td>\n",
       "      <td>61.623146</td>\n",
       "      <td>42.221630</td>\n",
       "      <td>25.632828</td>\n",
       "      <td>16.337782</td>\n",
       "      <td>15.002048</td>\n",
       "      <td>18.738730</td>\n",
       "      <td>23.003593</td>\n",
       "      <td>24.039800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.748103</td>\n",
       "      <td>2.922751</td>\n",
       "      <td>2.290715</td>\n",
       "      <td>1.166961</td>\n",
       "      <td>0.225971</td>\n",
       "      <td>0.042497</td>\n",
       "      <td>0.699116</td>\n",
       "      <td>1.713670</td>\n",
       "      <td>2.332496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-562.58900</td>\n",
       "      <td>88.77356</td>\n",
       "      <td>71.557740</td>\n",
       "      <td>49.522438</td>\n",
       "      <td>29.541950</td>\n",
       "      <td>16.664858</td>\n",
       "      <td>12.350879</td>\n",
       "      <td>14.427670</td>\n",
       "      <td>18.631382</td>\n",
       "      <td>20.879950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984788</td>\n",
       "      <td>1.662023</td>\n",
       "      <td>2.113323</td>\n",
       "      <td>2.125078</td>\n",
       "      <td>1.752352</td>\n",
       "      <td>1.235468</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.692907</td>\n",
       "      <td>0.788556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-489.47345</td>\n",
       "      <td>65.72582</td>\n",
       "      <td>57.030285</td>\n",
       "      <td>45.383488</td>\n",
       "      <td>33.820340</td>\n",
       "      <td>24.795256</td>\n",
       "      <td>19.436210</td>\n",
       "      <td>17.373821</td>\n",
       "      <td>17.174334</td>\n",
       "      <td>17.152473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.122123</td>\n",
       "      <td>2.094586</td>\n",
       "      <td>2.164926</td>\n",
       "      <td>2.183312</td>\n",
       "      <td>2.057845</td>\n",
       "      <td>1.794090</td>\n",
       "      <td>1.474256</td>\n",
       "      <td>1.199110</td>\n",
       "      <td>1.032410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1           2          3          4          5  \\\n",
       "0 -577.74457  116.68117   82.454210  40.931873   7.485605  -7.887007   \n",
       "1 -628.81630  136.51126  100.357864  56.209590  19.551243   0.428206   \n",
       "2 -601.18340   77.22223   61.623146  42.221630  25.632828  16.337782   \n",
       "3 -562.58900   88.77356   71.557740  49.522438  29.541950  16.664858   \n",
       "4 -489.47345   65.72582   57.030285  45.383488  33.820340  24.795256   \n",
       "\n",
       "           6          7          8          9  ...        31        32  \\\n",
       "0  -4.491601  10.008358  24.508472  30.438593  ...  5.994569  5.839570   \n",
       "1  -0.259094  10.158183  21.104572  24.655876  ...  3.507886  2.841200   \n",
       "2  15.002048  18.738730  23.003593  24.039800  ...  2.748103  2.922751   \n",
       "3  12.350879  14.427670  18.631382  20.879950  ...  0.984788  1.662023   \n",
       "4  19.436210  17.373821  17.174334  17.152473  ...  2.122123  2.094586   \n",
       "\n",
       "         33        34        35        36        37        38        39  0.1  \n",
       "0  3.671601  0.848826 -1.004319 -1.004396  0.530715  2.398161  3.331668    1  \n",
       "1  1.227278 -0.146953 -0.405241  0.449801  1.629177  2.186590  1.692338    1  \n",
       "2  2.290715  1.166961  0.225971  0.042497  0.699116  1.713670  2.332496    1  \n",
       "3  2.113323  2.125078  1.752352  1.235468  0.835051  0.692907  0.788556    1  \n",
       "4  2.164926  2.183312  2.057845  1.794090  1.474256  1.199110  1.032410    1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"0.1\": \"labels\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2575\n",
       "1     665\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.title(\"Distribution or Normal and Abnormal Heart sounds\",fontsize= 16)\n",
    "plt.xticks(fontsize=14,rotation=0)\n",
    "# for spine in plt.gca().spines.values():\n",
    "#     spine.set_visible(False)\n",
    "plt.yticks([])\n",
    "sns.countplot(x='labels',data=df,palette=\"Set2\")\n",
    "plt.show()\n",
    "# for p in ax.patches:\n",
    "#     width, height = p.get_width(), p.get_height()\n",
    "#     x, y = p.get_xy() \n",
    "#     ax.text(x+width/2, \n",
    "#             y+height/2, \n",
    "#             '{:.0f}'.format(height), \n",
    "#             horizontalalignment='center', \n",
    "#             verticalalignment='center')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Dataset and balance the y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:40]\n",
    "# y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-577.74457</td>\n",
       "      <td>116.68117</td>\n",
       "      <td>82.454210</td>\n",
       "      <td>40.931873</td>\n",
       "      <td>7.485605</td>\n",
       "      <td>-7.887007</td>\n",
       "      <td>-4.491601</td>\n",
       "      <td>10.008358</td>\n",
       "      <td>24.508472</td>\n",
       "      <td>30.438593</td>\n",
       "      <td>...</td>\n",
       "      <td>3.970105</td>\n",
       "      <td>5.994569</td>\n",
       "      <td>5.839570</td>\n",
       "      <td>3.671601</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>-1.004319</td>\n",
       "      <td>-1.004396</td>\n",
       "      <td>0.530715</td>\n",
       "      <td>2.398161</td>\n",
       "      <td>3.331668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-628.81630</td>\n",
       "      <td>136.51126</td>\n",
       "      <td>100.357864</td>\n",
       "      <td>56.209590</td>\n",
       "      <td>19.551243</td>\n",
       "      <td>0.428206</td>\n",
       "      <td>-0.259094</td>\n",
       "      <td>10.158183</td>\n",
       "      <td>21.104572</td>\n",
       "      <td>24.655876</td>\n",
       "      <td>...</td>\n",
       "      <td>2.601242</td>\n",
       "      <td>3.507886</td>\n",
       "      <td>2.841200</td>\n",
       "      <td>1.227278</td>\n",
       "      <td>-0.146953</td>\n",
       "      <td>-0.405241</td>\n",
       "      <td>0.449801</td>\n",
       "      <td>1.629177</td>\n",
       "      <td>2.186590</td>\n",
       "      <td>1.692338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-601.18340</td>\n",
       "      <td>77.22223</td>\n",
       "      <td>61.623146</td>\n",
       "      <td>42.221630</td>\n",
       "      <td>25.632828</td>\n",
       "      <td>16.337782</td>\n",
       "      <td>15.002048</td>\n",
       "      <td>18.738730</td>\n",
       "      <td>23.003593</td>\n",
       "      <td>24.039800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.034146</td>\n",
       "      <td>2.748103</td>\n",
       "      <td>2.922751</td>\n",
       "      <td>2.290715</td>\n",
       "      <td>1.166961</td>\n",
       "      <td>0.225971</td>\n",
       "      <td>0.042497</td>\n",
       "      <td>0.699116</td>\n",
       "      <td>1.713670</td>\n",
       "      <td>2.332496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-562.58900</td>\n",
       "      <td>88.77356</td>\n",
       "      <td>71.557740</td>\n",
       "      <td>49.522438</td>\n",
       "      <td>29.541950</td>\n",
       "      <td>16.664858</td>\n",
       "      <td>12.350879</td>\n",
       "      <td>14.427670</td>\n",
       "      <td>18.631382</td>\n",
       "      <td>20.879950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.984788</td>\n",
       "      <td>1.662023</td>\n",
       "      <td>2.113323</td>\n",
       "      <td>2.125078</td>\n",
       "      <td>1.752352</td>\n",
       "      <td>1.235468</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.692907</td>\n",
       "      <td>0.788556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-489.47345</td>\n",
       "      <td>65.72582</td>\n",
       "      <td>57.030285</td>\n",
       "      <td>45.383488</td>\n",
       "      <td>33.820340</td>\n",
       "      <td>24.795256</td>\n",
       "      <td>19.436210</td>\n",
       "      <td>17.373821</td>\n",
       "      <td>17.174334</td>\n",
       "      <td>17.152473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.368080</td>\n",
       "      <td>2.122123</td>\n",
       "      <td>2.094586</td>\n",
       "      <td>2.164926</td>\n",
       "      <td>2.183312</td>\n",
       "      <td>2.057845</td>\n",
       "      <td>1.794090</td>\n",
       "      <td>1.474256</td>\n",
       "      <td>1.199110</td>\n",
       "      <td>1.032410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1           2          3          4          5  \\\n",
       "0 -577.74457  116.68117   82.454210  40.931873   7.485605  -7.887007   \n",
       "1 -628.81630  136.51126  100.357864  56.209590  19.551243   0.428206   \n",
       "2 -601.18340   77.22223   61.623146  42.221630  25.632828  16.337782   \n",
       "3 -562.58900   88.77356   71.557740  49.522438  29.541950  16.664858   \n",
       "4 -489.47345   65.72582   57.030285  45.383488  33.820340  24.795256   \n",
       "\n",
       "           6          7          8          9  ...        30        31  \\\n",
       "0  -4.491601  10.008358  24.508472  30.438593  ...  3.970105  5.994569   \n",
       "1  -0.259094  10.158183  21.104572  24.655876  ...  2.601242  3.507886   \n",
       "2  15.002048  18.738730  23.003593  24.039800  ...  2.034146  2.748103   \n",
       "3  12.350879  14.427670  18.631382  20.879950  ...  0.486486  0.984788   \n",
       "4  19.436210  17.373821  17.174334  17.152473  ...  2.368080  2.122123   \n",
       "\n",
       "         32        33        34        35        36        37        38  \\\n",
       "0  5.839570  3.671601  0.848826 -1.004319 -1.004396  0.530715  2.398161   \n",
       "1  2.841200  1.227278 -0.146953 -0.405241  0.449801  1.629177  2.186590   \n",
       "2  2.922751  2.290715  1.166961  0.225971  0.042497  0.699116  1.713670   \n",
       "3  1.662023  2.113323  2.125078  1.752352  1.235468  0.835051  0.692907   \n",
       "4  2.094586  2.164926  2.183312  2.057845  1.794090  1.474256  1.199110   \n",
       "\n",
       "         39  \n",
       "0  3.331668  \n",
       "1  1.692338  \n",
       "2  2.332496  \n",
       "3  0.788556  \n",
       "4  1.032410  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "A_train,A_test,b_train,b_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       526\n",
      "           1       0.00      0.00      0.00       122\n",
      "\n",
      "    accuracy                           0.81       648\n",
      "   macro avg       0.41      0.50      0.45       648\n",
      "weighted avg       0.66      0.81      0.73       648\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import svm\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import classification_report\n",
    "model = SVC(kernel='rbf', random_state=0)   # SVC Model\n",
    "model.fit(A_train, b_train) \n",
    "b_pred = model.predict(A_test)\n",
    "print('SVM')\n",
    "print('---------------------')\n",
    "print(classification_report(b_test, b_pred))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see that as data is imbalanced it gives biased results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SMOTE Algorithm to balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=40)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5150, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5150, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_sm,y_sm,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVC without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.68      0.74       526\n",
      "           1       0.71      0.83      0.77       504\n",
      "\n",
      "    accuracy                           0.75      1030\n",
      "   macro avg       0.76      0.75      0.75      1030\n",
      "weighted avg       0.76      0.75      0.75      1030\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC  \n",
    "model = SVC(kernel='rbf', random_state=0)   # SVC Model\n",
    "model.fit(X_train, y_train) \n",
    "y_pred = model.predict(X_test)\n",
    "print('SVM')\n",
    "print('---------------------')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.5026699\n",
      " 0.5026699  0.5026699  0.7288835  0.69150485 0.5026699  0.5026699\n",
      " 0.84684466 0.84757282 0.7868932  0.63956311 0.83665049 0.95242718\n",
      " 0.90072816 0.86043689 0.67742718 0.86237864 0.95339806 0.90461165\n",
      " 0.86334951 0.69296117 0.87281553 0.95461165 0.90703883 0.86796117\n",
      " 0.69296117 0.87281553 0.95703883 0.93398058 0.87985437]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=0.01, random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       526\n",
      "           1       0.94      0.97      0.96       504\n",
      "\n",
      "    accuracy                           0.96      1030\n",
      "   macro avg       0.96      0.96      0.96      1030\n",
      "weighted avg       0.96      0.96      0.96      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "  \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0,0.01,0.1,0.8,1,1.2,10], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':['rbf'] } \n",
    "  \n",
    "grid = GridSearchCV(svm.SVC(random_state=0), param_grid,verbose=1,n_jobs=-1,cv=10)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[497  29]\n",
      " [ 16 488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for test  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(grid,X_test, y_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('C:/Users/heera/Desktop/Dissertation/Data Physionet/validation/merged_val.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-577.74457</td>\n",
       "      <td>116.68117</td>\n",
       "      <td>82.454210</td>\n",
       "      <td>40.931873</td>\n",
       "      <td>7.485605</td>\n",
       "      <td>-7.887007</td>\n",
       "      <td>-4.491601</td>\n",
       "      <td>10.008358</td>\n",
       "      <td>24.508472</td>\n",
       "      <td>30.438593</td>\n",
       "      <td>...</td>\n",
       "      <td>5.994569</td>\n",
       "      <td>5.839570</td>\n",
       "      <td>3.671601</td>\n",
       "      <td>0.848826</td>\n",
       "      <td>-1.004319</td>\n",
       "      <td>-1.004396</td>\n",
       "      <td>0.530715</td>\n",
       "      <td>2.398161</td>\n",
       "      <td>3.331668</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-628.81630</td>\n",
       "      <td>136.51126</td>\n",
       "      <td>100.357864</td>\n",
       "      <td>56.209590</td>\n",
       "      <td>19.551243</td>\n",
       "      <td>0.428206</td>\n",
       "      <td>-0.259094</td>\n",
       "      <td>10.158183</td>\n",
       "      <td>21.104572</td>\n",
       "      <td>24.655876</td>\n",
       "      <td>...</td>\n",
       "      <td>3.507886</td>\n",
       "      <td>2.841200</td>\n",
       "      <td>1.227278</td>\n",
       "      <td>-0.146953</td>\n",
       "      <td>-0.405241</td>\n",
       "      <td>0.449801</td>\n",
       "      <td>1.629177</td>\n",
       "      <td>2.186590</td>\n",
       "      <td>1.692338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-601.18340</td>\n",
       "      <td>77.22223</td>\n",
       "      <td>61.623146</td>\n",
       "      <td>42.221630</td>\n",
       "      <td>25.632828</td>\n",
       "      <td>16.337782</td>\n",
       "      <td>15.002048</td>\n",
       "      <td>18.738730</td>\n",
       "      <td>23.003593</td>\n",
       "      <td>24.039800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.748103</td>\n",
       "      <td>2.922751</td>\n",
       "      <td>2.290715</td>\n",
       "      <td>1.166961</td>\n",
       "      <td>0.225971</td>\n",
       "      <td>0.042497</td>\n",
       "      <td>0.699116</td>\n",
       "      <td>1.713670</td>\n",
       "      <td>2.332496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-562.58900</td>\n",
       "      <td>88.77356</td>\n",
       "      <td>71.557740</td>\n",
       "      <td>49.522438</td>\n",
       "      <td>29.541950</td>\n",
       "      <td>16.664858</td>\n",
       "      <td>12.350879</td>\n",
       "      <td>14.427670</td>\n",
       "      <td>18.631382</td>\n",
       "      <td>20.879950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984788</td>\n",
       "      <td>1.662023</td>\n",
       "      <td>2.113323</td>\n",
       "      <td>2.125078</td>\n",
       "      <td>1.752352</td>\n",
       "      <td>1.235468</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.692907</td>\n",
       "      <td>0.788556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-489.47345</td>\n",
       "      <td>65.72582</td>\n",
       "      <td>57.030285</td>\n",
       "      <td>45.383488</td>\n",
       "      <td>33.820340</td>\n",
       "      <td>24.795256</td>\n",
       "      <td>19.436210</td>\n",
       "      <td>17.373821</td>\n",
       "      <td>17.174334</td>\n",
       "      <td>17.152473</td>\n",
       "      <td>...</td>\n",
       "      <td>2.122123</td>\n",
       "      <td>2.094586</td>\n",
       "      <td>2.164926</td>\n",
       "      <td>2.183312</td>\n",
       "      <td>2.057845</td>\n",
       "      <td>1.794090</td>\n",
       "      <td>1.474256</td>\n",
       "      <td>1.199110</td>\n",
       "      <td>1.032410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1           2          3          4          5  \\\n",
       "0 -577.74457  116.68117   82.454210  40.931873   7.485605  -7.887007   \n",
       "1 -628.81630  136.51126  100.357864  56.209590  19.551243   0.428206   \n",
       "2 -601.18340   77.22223   61.623146  42.221630  25.632828  16.337782   \n",
       "3 -562.58900   88.77356   71.557740  49.522438  29.541950  16.664858   \n",
       "4 -489.47345   65.72582   57.030285  45.383488  33.820340  24.795256   \n",
       "\n",
       "           6          7          8          9  ...        31        32  \\\n",
       "0  -4.491601  10.008358  24.508472  30.438593  ...  5.994569  5.839570   \n",
       "1  -0.259094  10.158183  21.104572  24.655876  ...  3.507886  2.841200   \n",
       "2  15.002048  18.738730  23.003593  24.039800  ...  2.748103  2.922751   \n",
       "3  12.350879  14.427670  18.631382  20.879950  ...  0.984788  1.662023   \n",
       "4  19.436210  17.373821  17.174334  17.152473  ...  2.122123  2.094586   \n",
       "\n",
       "         33        34        35        36        37        38        39  0.1  \n",
       "0  3.671601  0.848826 -1.004319 -1.004396  0.530715  2.398161  3.331668    1  \n",
       "1  1.227278 -0.146953 -0.405241  0.449801  1.629177  2.186590  1.692338    1  \n",
       "2  2.290715  1.166961  0.225971  0.042497  0.699116  1.713670  2.332496    1  \n",
       "3  2.113323  2.125078  1.752352  1.235468  0.835051  0.692907  0.788556    1  \n",
       "4  2.164926  2.183312  2.057845  1.794090  1.474256  1.199110  1.032410    1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val= df_val.rename(columns={\"0.1\": \"labels\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    151\n",
       "0    150\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv = df_val.iloc[:,0:40]\n",
    "# y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "yv= df_val[[\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3240, 40)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = X\n",
    "y_train =y\n",
    "l_test =Xv\n",
    "m_test =yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9867109634551495"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Accuracy\n",
    "grid.score(l_test.values, m_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9563106796116505"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Accuracy\n",
    "grid.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusin matrix for validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(grid,l_test, m_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([df, df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1           2           3          4          5           6           7          8          9          10         11         12          13          14         15         16         17         18         19         20         21         22         23         24        25        26         27         28         29         30         31         32         33        34         35         36         37         38         39         labels\n",
       "-769.55676  138.452220  107.299640  67.536960  31.606808   8.432062    0.287191   3.003927   9.060970   11.771116  8.391644   0.722520   -6.784737   -10.058901  -7.784902  -1.906820  3.795021   6.042208   3.893194   -0.921731  -5.213430  -6.262261  -3.316064   2.128430  7.297077  9.709415   8.436174   4.403301  -0.300409  -3.612047  -4.487105  -3.212341  -0.990804  0.856485   1.584437   1.270859   0.576312   0.239978   0.627463   1.557677  1         2\n",
       "-555.07166  108.996550  76.340800   37.841454  8.742563   -1.908288    5.051618   20.603024  33.270374  35.416650  26.637316  12.732757   1.402862   -2.446099    0.971424   7.367223  11.674855  11.268613  7.139828    2.597324   0.680564   2.141463   5.241895   7.269388  6.548086  3.524748   0.278221  -1.064111   0.185726   2.904328   5.068111   5.216750   3.411816  1.059878  -0.196248   0.324878   1.911019   3.055449   2.611702   0.656384  1         2\n",
       "-550.94135  90.938370   70.272415   44.134968  20.987045   6.907995    3.471746   7.781673   14.473883  18.579216  17.750093  12.837497   6.785624    2.663249    1.981330   4.142600  7.133051   8.874148   8.391196    6.174859   3.647055   2.174602   2.274854   3.443678  4.612290  4.876625   4.026786   2.583049   1.383216   1.030529   1.553538   2.457829   3.089240  3.048069   2.397006   1.562653   1.027888   1.029664   1.446995   1.920872  1         2\n",
       "-440.62128  40.084286   38.439472   36.020023  33.122010   29.974860   26.758718  23.635742  20.733704  18.114704  15.782214  13.718232   11.906420   10.330379   8.971573   7.817870  6.867379   6.118819   5.560577    5.169246   4.912479   4.750030   4.637518   4.536860  4.426288  4.301614   4.170505   4.046180   3.941748   3.863921   3.809046   3.765178   3.718008  3.655371   3.569074   3.456238   3.320098   3.168409   3.010096   2.852927  1         2\n",
       "-475.97495  90.567116   71.885900   48.431860  26.807077   12.444874   7.346555   9.804691   15.686553  20.455150  21.261478  17.782532   11.865628   6.195775    2.878476   2.527252  4.255755   6.435188   7.647373    7.356287   5.963440   4.388149   3.433218   3.359484  3.853574  4.333530   4.357231   3.866993   3.173082   2.694011   2.673078   3.036239   3.468886  3.634304   3.389720   2.866369   2.368352   2.174886   2.364427   2.778181  1         2\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
       "-435.85760  61.230003   54.884357   46.370407  37.801483   30.777560   25.935572  22.943619  20.854880  18.657679  15.786161  12.345575   8.953619    6.331352    4.903178   4.607414  4.970922   5.373536   5.354525    4.803334   3.947251   3.170412   2.786992   2.890941  3.339673  3.855894   4.180664   4.193935   3.945492   3.596714   3.321477   3.222815   3.299004  3.463499   3.599923   3.620348   3.498920   3.271781   3.012771   2.799969  0         1\n",
       "-435.96994  120.044040  87.823746   47.896225  14.133237  -3.992914   -4.953242   5.378417   17.682460  24.217700  22.251860  14.364859   5.933103    1.579619    2.692214   7.214856  11.459495  12.569868  10.093326   5.864680   2.523939   1.767068   3.437921   5.900079  7.276931  6.665474   4.566016   2.362813   1.312528   1.752615   3.010560   3.982155   3.916471  2.867046   1.552863   0.791938   0.934938   1.678591   2.343191   2.377364  1         1\n",
       "-435.98110  94.412690   72.053300   44.177710  20.314482   7.069631    5.640433   12.075192  19.903110  23.593275  21.029701  13.890261   6.034224    1.032941    0.281236   2.615472  5.411476   6.321868   4.576371    1.171551  -1.992297  -3.371136  -2.641335  -0.718878  0.955962  1.340629   0.343527  -1.266398  -2.446505  -2.542136  -1.618728  -0.317110   0.607964  0.741652   0.187484  -0.588261  -1.094775  -1.103420  -0.722730  -0.259747  0         1\n",
       "-435.99893  105.765816  83.048410   54.639824  29.799433   15.017647   11.578072  15.795663  21.528740  23.534520  19.878387  12.280504   4.508973   -0.043498   -0.194952   2.692707  5.860115   6.923718   5.172950    1.715137  -1.455840  -2.779396  -2.005978  -0.163499  1.248311  1.246806  -0.087201  -1.787704  -2.714415  -2.294350  -0.826932   0.789555   1.674842  1.504456   0.639141  -0.192606  -0.408405   0.068064   0.815368   1.247438  0         1\n",
       "-452.70453  50.806526   46.225260   39.904053  33.292130   27.612768   23.494703  20.880291  19.213580  17.791035  16.103195  14.023145   11.784713   9.794170    8.387894   7.658630  7.425584   7.345800   7.095399    6.522226   5.696352   4.844677   4.216146   3.953605  4.034934  4.302556   4.553405   4.635752   4.504627   4.216279   3.875808   3.573186   3.342646  3.162041   2.984508   2.778099   2.548357   2.332442   2.172108   2.084830  0         1\n",
       "Length: 3240, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa = dataset.iloc[:,0:40]\n",
    "# y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = dataset[[\"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=40)\n",
    "X_sma, y_sma = sm.fit_resample(Xa, ya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traina,X_testa,y_traina,y_testa=train_test_split(X_sma,y_sma,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index:  [   1    2    3 ... 3237 3238 3239] \n",
      "\n",
      "Test Index:  [   0   14   17   26   30   32   33   44   45   51   52   63   70   76\n",
      "   93  102  120  134  139  144  149  152  170  173  174  178  179  183\n",
      "  184  192  194  203  211  214  218  229  239  240  251  254  256  257\n",
      "  263  270  279  289  291  298  299  309  314  321  322  325  331  332\n",
      "  346  354  387  411  414  416  433  438  442  449  450  457  463  478\n",
      "  479  485  486  495  501  506  507  527  528  538  554  568  581  599\n",
      "  602  605  610  611  612  655  665  670  679  691  693  705  729  746\n",
      "  756  765  772  785  789  794  803  811  829  839  844  867  871  881\n",
      "  887  927  942  944  945  962  969  978  990  999 1003 1006 1017 1027\n",
      " 1034 1042 1044 1052 1053 1057 1064 1084 1108 1116 1117 1127 1161 1173\n",
      " 1181 1188 1192 1210 1221 1244 1255 1258 1264 1270 1278 1283 1298 1309\n",
      " 1313 1317 1330 1336 1338 1359 1362 1366 1373 1381 1404 1412 1419 1421\n",
      " 1427 1429 1444 1447 1451 1472 1474 1483 1491 1502 1503 1509 1510 1518\n",
      " 1554 1556 1572 1609 1620 1623 1624 1626 1627 1644 1684 1694 1703 1713\n",
      " 1714 1716 1717 1741 1745 1749 1770 1775 1788 1791 1800 1820 1825 1844\n",
      " 1849 1860 1861 1876 1878 1902 1924 1929 1949 1954 1956 1960 1963 1983\n",
      " 1999 2005 2015 2018 2043 2045 2046 2089 2092 2093 2097 2102 2121 2153\n",
      " 2163 2174 2203 2212 2213 2240 2251 2256 2279 2309 2316 2330 2332 2335\n",
      " 2339 2345 2365 2375 2406 2408 2412 2416 2441 2464 2471 2473 2476 2519\n",
      " 2538 2542 2547 2551 2574 2580 2602 2619 2620 2644 2654 2683 2726 2743\n",
      " 2746 2751 2752 2753 2759 2769 2820 2823 2841 2844 2846 2875 2881 2890\n",
      " 2920 2928 2946 2947 2950 2954 2964 2987 3000 3002 3013 3014 3018 3036\n",
      " 3038 3074 3079 3080 3083 3085 3088 3097 3136 3140 3148 3158 3220 3223\n",
      " 3229 3232]\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.79475309\n",
      " 0.79475309 0.79475309 0.79475309 0.79475309 0.79475309 0.79475309\n",
      " 0.7962963  0.79845679 0.79382716 0.79475309 0.79598765 0.83703704\n",
      " 0.86049383 0.80679012 0.79475309 0.79598765 0.83734568 0.85895062\n",
      " 0.81111111 0.79475309 0.7962963  0.8367284  0.85648148 0.82098765\n",
      " 0.79475309 0.79845679 0.83981481 0.85       0.86450617]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-0d0ef5a2d175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test Index: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for train_index, test_index in cv.split(X):\n",
    "    print(\"Train Index: \", train_index, \"\\n\")\n",
    "    print(\"Test Index: \", test_index)\n",
    "    grid.fit(X_train, y_train)\n",
    "    scores.append(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.55802752\n",
      " 0.54518349 0.6146789  0.78211009 0.74357798 0.55802752 0.54678899\n",
      " 0.90389908 0.91651376 0.84862385 0.69954128 0.85986239 0.96100917\n",
      " 0.94862385 0.925      0.72362385 0.87637615 0.96146789 0.94908257\n",
      " 0.92706422 0.7337156  0.88646789 0.96146789 0.94931193 0.93027523\n",
      " 0.7337156  0.88692661 0.96192661 0.96169725 0.9440367 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.53486239\n",
      " 0.53440367 0.57798165 0.70183486 0.61811927 0.53486239 0.53440367\n",
      " 0.81972477 0.79426606 0.72110092 0.69426606 0.86307339 0.94633028\n",
      " 0.8587156  0.7706422  0.71880734 0.88165138 0.94954128 0.86444954\n",
      " 0.77316514 0.72844037 0.8896789  0.95137615 0.87133028 0.77866972\n",
      " 0.72844037 0.89013761 0.95688073 0.91949541 0.82568807]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.58394495\n",
      " 0.56055046 0.5690367  0.69357798 0.62522936 0.58394495 0.56055046\n",
      " 0.81376147 0.77201835 0.71330275 0.71330275 0.86559633 0.93876147\n",
      " 0.8559633  0.76513761 0.73142202 0.88394495 0.94380734 0.86009174\n",
      " 0.76834862 0.74059633 0.89357798 0.9456422  0.8646789  0.77362385\n",
      " 0.74059633 0.89426606 0.95068807 0.91582569 0.81146789]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.59977064\n",
      " 0.58669725 0.60206422 0.7043578  0.62775229 0.59977064 0.58669725\n",
      " 0.81880734 0.7690367  0.71995413 0.71376147 0.86720183 0.94174312\n",
      " 0.85068807 0.76100917 0.73188073 0.88394495 0.94426606 0.85504587\n",
      " 0.76834862 0.74266055 0.89266055 0.94655963 0.85802752 0.77178899\n",
      " 0.74243119 0.89357798 0.9516055  0.91192661 0.80940367]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 350.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.56100917\n",
      " 0.54770642 0.58486239 0.7266055  0.6603211  0.56100917 0.54770642\n",
      " 0.82866972 0.83142202 0.75573394 0.71582569 0.86674312 0.94243119\n",
      " 0.87270642 0.8337156  0.73440367 0.88188073 0.94334862 0.87981651\n",
      " 0.83807339 0.74610092 0.89059633 0.94426606 0.88577982 0.83899083\n",
      " 0.74610092 0.89151376 0.9483945  0.92178899 0.85366972]\n",
      "  warnings.warn(\n",
      "C:\\Users\\heera\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.79908257, 0.98165138, 0.99449541, 0.99082569, 0.96330275])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(grid, X_sma, y_sma, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= np.array([0.79908257, 0.98165138, 0.99449541, 0.99082569, 0.96330275])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94587156"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
